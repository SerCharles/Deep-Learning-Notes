---
typora-root-url: ./
---

# CNN应用

## 1.人脸识别

两种任务：人脸识别和人脸确认

**人脸识别：**

​	封闭集：DeepFace：先用图形学方法进行人脸对齐，然后用CNN网络进行训练

​	开放集：Center Loss：损失函数增加了一项，代表x与每一类的距离（center loss），保证让分类高内聚低耦合，这样可以解决开放集问题（距离每个类都远就不属于任何一类）
$$
\frac{\lambda}{2}\sum_{i=1}^{m}||x_i-c_{y_i}||_2^2
$$
​					Sphere Face：假设所有人脸分布在一个球面流形上，尽量保证不同类的人脸距离足够远--在球面上夹角足够大。实现方法是这样修改loss function，增大不同类的夹角。

![sphere](/sphere.png)

**人脸确认：**

​	FaceNet：先将人脸数据输入CNN网络，然后进行L2正则化（消除向量范数对距离的影响）和embedding，最后用Triplet Loss来分类

​	Triplet Loss定义如下，目标是让positive（正例）与你的anchor更接近，negative（负例）与你的anchor更远，而且至少有a的距离差别，以确保能分出正例和负例
$$
\sum_i^N[||f(x_i^a)-f(x_i^p)||^2 - ||f(x_i^a)-f(x_i^n)||^2 + \alpha]_+
$$
这张图能说明人脸确认的triplet到底要干什么

![triplet](/triplet.png)

## 2.图像分割

基本思路：给每个像素点做分类---需要下采样（识别高级特征）之后上采样（每个点赋值）

**FCN：**先用CNN下采样，识别不同级别的特征；之后用转置卷积上采样。

问题：下采样识别高级特征，会丢失细节。解决方案：**将高级特征和低级特征连接起来**。(高级特征channel多但是大小小，用上采样增加大小；低级特征大小大但是channel少，1*1卷积增加channel)

![FCN](/FCN.png)

**Deeplab：**另一种解决之前问题的方法：用dilated卷积来增大高级特征的feature大小以及增大感受野，保证高级特征不丢失信息。同时用spatial pyramid pooling来连接不同等级的特征

**Unet：**FCN改进版：将下采样和上采样阶段对应大小的特征逐层连接（上采样的时候，比如图片大小是128*128，那么只需要下采样阶段128* * 128那么大的细节就够了，更大图片的细节没必要），广泛用于生物医学图像分割

![UNet](/UNet.png)

**上色：**本质也是分割问题，不过采用multinomial classification损失，对每个像素取平均
$$
L = -\frac{1}{HW}\sum_{h,w}\sum_{q}Z_{h,w,q}log(Z^{'}_{h,w,q})
$$
还可以对不同的颜色加权，以考虑稀有的颜色

## 3.物体检测

需要完成的任务：寻找备选区域，识别区域内物体，优化区域边界

**R-CNN：**传统方法寻找备选区域（2000多个）+每个区域CNN识别（区域太多，太慢）+线性回归优化边界

**Fast R-CNN：**

- ​		先CNN提取特征，再传统方法寻找备选区域
- ​		备选区域大小不一致，而识别网络要求大小一致？ROI Pooling，用pooling将区域大小都变成一样
- ​		将区域CNN识别和优化边界统一起来，多任务同时学习

**RPN：**深度学习寻找备选区域

- ​	备选区域数目：6*6的高级特征图片，每个点作为anchor，找9个不同类型的图片，一共6 * 6 * 9个
- ​	训练任务：多任务学习，判断每个anchor是不是物体+优化选择边界
- ​	训练数据来源：用ground truth的信息，构造每个anchor是否是物体，还有边界数据的信息
- ​	使用RPN的整体流程：CNN提取特征--RPN寻找备选区域（小网络）--CNN进一步做物体分类和边界优化

**多阶段变为单阶段：**

​		YOLO：将RPN和最终网络结合，在寻找备选区域同时就完成了物体分类

​		SSD：改进YOLO，综合利用多个尺度的特征，**低级特征识别小物体，高级特征识别大物体**

​		FPN：将多个尺度特征用**1*1卷积，上采样**结合到一起来用于识别，能够同时识别小物体和大物体

​		RetinaNet：进一步改进，改进了损失函数，使得网络更加侧重于**较少的正例和较难识别的物体**，解决了训练样本正例负例不平衡的问题，还有识别难度不同的问题

**实例分割：**不仅要不同类别物体分割，还要具体识别每个物体（比如2个人应该被识别成不同的实例）

Mask R-CNN：

- ​		引入RolAlign，用双线性插值进一步改进边界识别
- ​		多任务学习，让图像分割和物体检测相互促进

## 4.图像风格化

**基础：**用内容图片和风格图片同时训练，2个识别准则：**内容损失函数**（强调逐像素匹配，**强调位置信息一致**），**风格损失函数**（用Cram矩阵，也就是先把特征变形成C*WH形式，再乘以转置，得到C * C形式。**忽略了位置信息**）

**改进：**

​		Instance Normalization：对图片的单一channel做Normalization，相当于**把图片白化，忽略了内容图片的颜色信息**。

​		Conditional：对于多种风格，每一种风格设置独特的r和B参数

​		Adaptive：用风格图片的方差，均值分别作为r，B

**加速：**在完成风格迁移学习之后，**把生成的结果图片作为训练数据**，训练一个图像变形网络把输入图片变成目标图片--仅仅适用于某个风格，但是非常快

**应用：**超分辨率，把高分辨率作为风格，低分辨率图片作为内容

## 5.视频

Two-Stream 卷积：两条路径，一条是单一图片的spatial stream，另一条是对应的多个光流的temporal stream。用的都是2d卷积

I3D：也是两条路径，不过都用的是3d卷积，而且图片也不再是单一图片，而是多张图片了

R（2+1）D：融合了temporal与spacial卷积，作为一个新的单元

![R(2+1)D](/R(2+1)D.png)

动作识别与检测：最简单的是当做多张图片，用2D方法识别与检测

​		Slow Fast网络：较慢的视频为主，较快的视频为辅，两者位于两条路径，但是快视频的channel较少，而且快的会被融入慢的之中。识别做得较好，检测较差。

![slowfast](/slowfast.png)

## 6.三维数据

**投影：**多个投影用同一个CNN提取特征+view pooling融合

**Volumetric：**用3D卷积识别特征，3D转置卷积重建，和2D图像分割等一样

**点云：两大难关：交换不变性，旋转不变性**

**交换不变性：**用max作为对称函数，有
$$
\forall f, \epsilon > 0, \exists h, \gamma, s.t.\\
|f(S) - \gamma(MAX\{h(x_i)\})|<\epsilon
$$
也就是用这样的一种网络结构，能够拟合任何点云分布

![pointnet](/pointnet.png)

**旋转不变性：**保证旋转矩阵是正交矩阵

方法：T-Net，输入d * N的点云数据，生成一个d * d的正交矩阵作为旋转变换矩阵，用正交损失函数来训练
$$
L_{reg}=||I-AA^T||_F^2
$$
**PointNet:**二者组合得到

​	每个h函数都是：点云---T-net输入变换--mlp提取特征--T-net特征变换--mlp提取特征（局部特征

​	之后用max函数得到全局特征

​	segmentation则是组合了局部和全局特征

**PointNet++：**以PointNet作为基本单元组合成复杂网络

**点云重建：**用2d图片重建3d点云

​		encoder：2DCNN网络

​		decoder：反转置卷积

​		**损失函数：Chamfer Distance**，用于度量两个集合每个点和最近点距离之和
$$
d_{CD}(S_1,S_2)=\sum_{x\in S_1}min_{y\in S_2}||x-y||^2_2 + \sum_{y\in S_2}min_{x\in S_1}||x-y||^2_2
$$

## 7.整体思维导图

